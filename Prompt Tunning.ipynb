{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":81369,"databundleVersionId":8796889,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Practice 5 - Parameter Efficient Tunning (ALBERT, DistillBERT) & Prompt Tuning","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### Dataset Load & Preprocessing","metadata":{}},{"cell_type":"code","source":"with open('/kaggle/input/2024-1-nlp-5/Korean_movie_reviews_2016.txt/Korean_movie_reviews_2016.txt', encoding='utf-8') as f:\n    docs = [doc.strip().split('\\t') for doc in f]\n    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n    texts, labels = zip(*docs)\n    \nwords_list = [doc.strip().split() for doc in texts]\nprint(words_list[:2])\nprint(len(texts))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:42:09.886788Z","iopub.execute_input":"2024-06-23T08:42:09.887554Z","iopub.status.idle":"2024-06-23T08:42:11.474995Z","shell.execute_reply.started":"2024-06-23T08:42:09.887507Z","shell.execute_reply":"2024-06-23T08:42:11.473880Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"[['부산', '행', '때문', '너무', '기대하고', '봤'], ['한국', '좀비', '영화', '어색하지', '않게', '만들어졌', '놀랍']]\n165384\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\ny_one_hot = to_categorical(labels)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:42:11.476516Z","iopub.execute_input":"2024-06-23T08:42:11.476825Z","iopub.status.idle":"2024-06-23T08:42:11.494891Z","shell.execute_reply.started":"2024-06-23T08:42:11.476799Z","shell.execute_reply":"2024-06-23T08:42:11.493858Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(texts, y_one_hot, test_size=0.2, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:42:11.496323Z","iopub.execute_input":"2024-06-23T08:42:11.496648Z","iopub.status.idle":"2024-06-23T08:42:11.571158Z","shell.execute_reply.started":"2024-06-23T08:42:11.496623Z","shell.execute_reply":"2024-06-23T08:42:11.570198Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## 실습 5.1 - Parameter Efficient Tuning with ALBERT","metadata":{}},{"cell_type":"markdown","source":"### Load Tokenizer & Dataset Split","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, TFAlbertForSequenceClassification\ntokenizer = BertTokenizer.from_pretrained(\"kykim/albert-kor-base\")","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:42:11.573651Z","iopub.execute_input":"2024-06-23T08:42:11.574057Z","iopub.status.idle":"2024-06-23T08:42:11.732792Z","shell.execute_reply.started":"2024-06-23T08:42:11.574023Z","shell.execute_reply":"2024-06-23T08:42:11.731933Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'AlbertTokenizer'. \nThe class this function is called from is 'BertTokenizer'.\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train_tokenized = tokenizer(X_train, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\nX_test_tokenized = tokenizer(X_test, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:42:11.734112Z","iopub.execute_input":"2024-06-23T08:42:11.734534Z","iopub.status.idle":"2024-06-23T08:43:12.079757Z","shell.execute_reply.started":"2024-06-23T08:42:11.734499Z","shell.execute_reply":"2024-06-23T08:43:12.078951Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Load Model","metadata":{}},{"cell_type":"code","source":"albert_model = TFAlbertForSequenceClassification.from_pretrained(\"kykim/albert-kor-base\", num_labels=2, from_pt=True)\nalbert_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:43:12.080966Z","iopub.execute_input":"2024-06-23T08:43:12.081282Z","iopub.status.idle":"2024-06-23T08:43:12.576205Z","shell.execute_reply.started":"2024-06-23T08:43:12.081256Z","shell.execute_reply":"2024-06-23T08:43:12.575277Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertForSequenceClassification: ['albert.embeddings.position_ids', 'sop_classifier.classifier.weight', 'sop_classifier.classifier.bias']\n- This IS expected if you are initializing TFAlbertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFAlbertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFAlbertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tf_albert_for_sequence_classification_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n albert (TFAlbertMainLayer)  multiple                  13186816  \n                                                                 \n dropout_29 (Dropout)        multiple                  0         \n                                                                 \n classifier (Dense)          multiple                  1538      \n                                                                 \n=================================================================\nTotal params: 13188354 (50.31 MB)\nTrainable params: 13188354 (50.31 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 실습 및 과제 5.1\n\nFinetune your ALBERT model with \"Korean_movie_reviews_2016.txt\" 데이터셋","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\n\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized), y_train))\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(X_test_tokenized), y_test))\n\ntrain_dataset = train_dataset.shuffle(len(X_train)).batch(32)\ntest_dataset = test_dataset.batch(32)\n\nloss = CategoricalCrossentropy(from_logits=True)\nalbert_model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n\nhistory = albert_model.fit(train_dataset, validation_data=test_dataset,epochs=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:43:12.577426Z","iopub.execute_input":"2024-06-23T08:43:12.577683Z","iopub.status.idle":"2024-06-23T08:54:05.981085Z","shell.execute_reply.started":"2024-06-23T08:43:12.577660Z","shell.execute_reply":"2024-06-23T08:54:05.980196Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"4135/4135 [==============================] - 653s 150ms/step - loss: 0.7119 - accuracy: 0.5112 - val_loss: 0.6992 - val_accuracy: 0.5263\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nalbert_model.evaluate(dict(X_test_tokenized), np.array(y_test))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:54:05.982382Z","iopub.execute_input":"2024-06-23T08:54:05.982699Z","iopub.status.idle":"2024-06-23T08:55:16.041238Z","shell.execute_reply.started":"2024-06-23T08:54:05.982670Z","shell.execute_reply":"2024-06-23T08:55:16.040348Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1034/1034 [==============================] - 70s 57ms/step - loss: 0.6992 - accuracy: 0.5263\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"[0.6991918683052063, 0.5262871384620667]"},"metadata":{}}]},{"cell_type":"code","source":"y_preds = albert_model.predict(dict(X_test_tokenized))\nprediction_probs = tf.nn.softmax(y_preds.logits,axis=1).numpy()\ny_predictions = np.argmax(prediction_probs, axis=1)\ny_test = np.argmax(y_test, axis=1)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_predictions, y_test))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:55:16.042334Z","iopub.execute_input":"2024-06-23T08:55:16.042611Z","iopub.status.idle":"2024-06-23T08:56:23.265535Z","shell.execute_reply.started":"2024-06-23T08:55:16.042588Z","shell.execute_reply":"2024-06-23T08:56:23.264565Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"1034/1034 [==============================] - 67s 56ms/step\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         0\n           1       1.00      0.53      0.69     33077\n\n    accuracy                           0.53     33077\n   macro avg       0.50      0.26      0.34     33077\nweighted avg       1.00      0.53      0.69     33077\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 실습 5.2 - Parameter Efficient Tuning with DistillBERT","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n\ntokenizer = DistilBertTokenizer.from_pretrained(\"monologg/distilkobert\")\n\nX_train_tokenized_DistillBERT = DistillBERT_tokenizer(X_train, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)\nX_test_tokenize_DistillBERT = DistillBERT_tokenizer(X_test, return_tensors=\"np\", max_length=30, padding='max_length', truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:56:26.326790Z","iopub.execute_input":"2024-06-23T08:56:26.327092Z","iopub.status.idle":"2024-06-23T08:58:02.613398Z","shell.execute_reply.started":"2024-06-23T08:56:26.327067Z","shell.execute_reply":"2024-06-23T08:58:02.612577Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Load Model & Training","metadata":{}},{"cell_type":"code","source":"model_distillBERT = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, from_pt=True)\nmodel_distillBERT.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:58:02.616242Z","iopub.execute_input":"2024-06-23T08:58:02.616606Z","iopub.status.idle":"2024-06-23T08:58:03.649798Z","shell.execute_reply.started":"2024-06-23T08:58:02.616573Z","shell.execute_reply":"2024-06-23T08:58:03.648890Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model: \"tf_distil_bert_for_sequence_classification_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n distilbert (TFDistilBertMa  multiple                  66362880  \n inLayer)                                                        \n                                                                 \n pre_classifier (Dense)      multiple                  590592    \n                                                                 \n classifier (Dense)          multiple                  1538      \n                                                                 \n dropout_49 (Dropout)        multiple                  0         \n                                                                 \n=================================================================\nTotal params: 66955010 (255.41 MB)\nTrainable params: 66955010 (255.41 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 실습 및 과제 5.2 \n\nFinetune your DistilKoBERT model with \"Korean_movie_reviews_2016.txt\" 데이터셋","metadata":{}},{"cell_type":"code","source":"distill_train_dataset = tf.data.Dataset.from_tensor_slices((dict(X_train_tokenized_DistillBERT), y_train))\ndistill_test_dataset = tf.data.Dataset.from_tensor_slices((dict(X_test_tokenize_DistillBERT), y_test))\n\ndistill_train_dataset = distill_train_dataset.shuffle(len(X_train)).batch(32)\ndistill_test_dataset = distill_test_dataset.batch(32)\n\nloss = CategoricalCrossentropy(from_logits=True)\nmodel_distillBERT.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n\nhistory_distill = model_distillBERT.fit(distill_train_dataset, validation_data=distill_test_dataset, epochs=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T08:58:03.650986Z","iopub.execute_input":"2024-06-23T08:58:03.651288Z","iopub.status.idle":"2024-06-23T09:04:22.518680Z","shell.execute_reply.started":"2024-06-23T08:58:03.651262Z","shell.execute_reply":"2024-06-23T09:04:22.517811Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"4135/4135 [==============================] - 379s 84ms/step - loss: 0.6925 - accuracy: 0.5232 - val_loss: 0.6918 - val_accuracy: 0.5263\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"model_distillBERT.evaluate(dict(X_test_tokenized), np.array(y_test))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:04:22.519850Z","iopub.execute_input":"2024-06-23T09:04:22.520162Z","iopub.status.idle":"2024-06-23T09:04:57.597714Z","shell.execute_reply.started":"2024-06-23T09:04:22.520116Z","shell.execute_reply":"2024-06-23T09:04:57.596888Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"1034/1034 [==============================] - 35s 29ms/step - loss: 0.6918 - accuracy: 0.5263\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"[0.6917791366577148, 0.5262871384620667]"},"metadata":{}}]},{"cell_type":"code","source":"y_preds = model_distillBERT.predict(dict(X_test_tokenized))\nprediction_probs = tf.nn.softmax(y_preds.logits,axis=1).numpy()\ny_predictions = np.argmax(prediction_probs, axis=1)\ny_test = np.argmax(y_test, axis=1)\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_predictions, y_test))","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:05:10.424917Z","iopub.execute_input":"2024-06-23T09:05:10.425307Z","iopub.status.idle":"2024-06-23T09:05:43.636512Z","shell.execute_reply.started":"2024-06-23T09:05:10.425274Z","shell.execute_reply":"2024-06-23T09:05:43.635527Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"1034/1034 [==============================] - 33s 28ms/step\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         0\n           1       1.00      0.53      0.69     33077\n\n    accuracy                           0.53     33077\n   macro avg       0.50      0.26      0.34     33077\nweighted avg       1.00      0.53      0.69     33077\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 실습 5.3\n\n- BERT 모델, ALBERT 모델, DistillBERT 모델의 크기와 성능을 비교하시오.","metadata":{}},{"cell_type":"markdown","source":"## 실습 5.4 - Prompt Engineering","metadata":{}},{"cell_type":"markdown","source":"### 5.4.1 - 프롬프트 작성 원칙\n모델이 최대한 정확하고 유용한 정보를 제공할 수 있도록 효과적인 프롬프트를 작성하는 것이 매우 중요합니다. 좋은 프롬프트를 만들기 위해서 다음과 같은 원칙을 고려합니다.\n\n1. 명확성과 구체성\n질문은 명확하고 구체적이어야 합니다. 모호한 질문은 LLM 모델의 혼란을 초래할 수 있기 때문입니다.\n예시: \"다음 주 주식 시장에 영향을 줄 수 있는 예정된 이벤트들은 무엇일까요?\"는 \"주식 시장에 대해 알려주세요.\"보다 더 구체적이고 명확한 질문입니다.\n2. 배경 정보를 포함\n모델이 문맥을 이해할 수 있도록 필요한 배경 정보를 제공하는 것이 좋습니다. 이는 환각 현상(hallucination)이 발생할 위험을 낮추고, 관련성 높은 응답을 생성하는 데 도움을 줍니다.\n예시: \"2020년 미국 대선의 결과를 바탕으로 현재 정치 상황에 대한 분석을 해주세요.\"\n3. 간결함\n핵심 정보에 초점을 맞추고, 불필요한 정보는 배제합니다. 프롬프트가 길어지면 모델이 덜 중요한 부분에 집중하거나 상당한 영향을 받는 문제가 발생할 수 있습니다.\n예시: \"2021년에 발표된 삼성전자의 ESG 보고서를 요약해주세요.\"\n4. 열린 질문 사용\n열린 질문을 통해 모델이 자세하고 풍부한 답변을 제공하도록 유도합니다. 단순한 '예' 또는 '아니오'로 대답할 수 있는 질문보다는 더 많은 정보를 제공하는 질문이 좋습니다.\n예시: \"신재생에너지에 대한 최신 연구 동향은 무엇인가요?\"\n5. 명확한 목표 설정\n얻고자 하는 정보나 결과의 유형을 정확하게 정의합니다. 이는 모델이 명확한 지침에 따라 응답을 생성하도록 돕습니다.\n예시: \"AI 윤리에 대한 문제점과 해결 방안을 요약하여 설명해주세요.\"\n6. 언어와 문체\n대화의 맥락에 적합한 언어와 문체를 선택합니다. 이는 모델이 상황에 맞는 표현을 선택하는데 도움이 됩니다.\n예시: 공식적인 보고서를 요청하는 경우, \"XX 보고서에 대한 전문적인 요약을 부탁드립니다.\"와 같이 정중한 문체를 사용합니다.\n\n### 예시: 제품 리뷰 요약\n* 지시: \"아래 제공된 제품 리뷰를 요약해주세요.\"\n* 예시: \"예를 들어, '이 제품은 매우 사용하기 편리하며 배터리 수명이 길다'라는 리뷰는 '사용 편리성과 긴 배터리 수명이 특징'으로 요약할 수 있습니다.\"\n* 맥락: \"리뷰는 스마트워치에 대한 것이며, 사용자 경험에 초점을 맞추고 있습니다.\"\n* 질문: \"이 리뷰를 바탕으로 스마트워치의 주요 장점을 두세 문장으로 요약해주세요.\"","metadata":{}},{"cell_type":"markdown","source":"### 5.4.2 openai langchain 시스템 이용하기","metadata":{}},{"cell_type":"code","source":"# openai langchain 시스템 이용하기\n!pip install langchain_core langchain_openai","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:06:28.889511Z","iopub.execute_input":"2024-06-23T09:06:28.890192Z","iopub.status.idle":"2024-06-23T09:06:45.396822Z","shell.execute_reply.started":"2024-06-23T09:06:28.890161Z","shell.execute_reply":"2024-06-23T09:06:45.395662Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting langchain_core\n  Downloading langchain_core-0.2.9-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain_openai\n  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (1.33)\nCollecting langsmith<0.2.0,>=0.1.75 (from langchain_core)\n  Downloading langsmith-0.1.81-py3-none-any.whl.metadata (13 kB)\nCollecting packaging<25,>=23.2 (from langchain_core)\n  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (2.5.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_core) (8.2.3)\nCollecting openai<2.0.0,>=1.26.0 (from langchain_openai)\n  Downloading openai-1.35.3-py3-none-any.whl.metadata (21 kB)\nCollecting tiktoken<1,>=0.7 (from langchain_openai)\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.75->langchain_core)\n  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.75->langchain_core) (2.32.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.9.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain_core) (2.14.6)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain_core) (1.26.18)\nDownloading langchain_core-0.2.9-py3-none-any.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.1.81-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.35.3-py3-none-any.whl (327 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, tiktoken, openai, langsmith, langchain_core, langchain_openai\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ndistributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.1 which is incompatible.\njupyterlab 4.2.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain_core-0.2.9 langchain_openai-0.1.9 langsmith-0.1.81 openai-1.35.3 orjson-3.10.5 packaging-24.1 tiktoken-0.7.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 5.4.3 템플릿 만들기","metadata":{}},{"cell_type":"code","source":"#문자열 템플릿 - 다음 예제는 langchain_core.prompts 모듈의 PromptTemplate 클래스를 사용하여, 'name'과 'age'라는 두 개의 변수를 포함하는 프롬프트 템플릿을 정의하고 있습니다. \n#이 템플릿을 이용하여 실제 입력값을 해당 위치에 채워 넣어 완성된 프롬프트를 생성하는 과정을 보여줍니다.\n\nfrom langchain_core.prompts import PromptTemplate\n\n# 'name'과 'age'라는 두 개의 변수를 사용하는 프롬프트 템플릿을 정의\ntemplate_text = \"안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\"\n\n# PromptTemplate 인스턴스를 생성\nprompt_template = PromptTemplate.from_template(template_text)\n\n# 템플릿에 값을 채워서 프롬프트를 완성\nfilled_prompt = prompt_template.format(name=\"홍길동\", age=30)\n\nfilled_prompt","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:06:51.730877Z","iopub.execute_input":"2024-06-23T09:06:51.731323Z","iopub.status.idle":"2024-06-23T09:06:52.303152Z","shell.execute_reply.started":"2024-06-23T09:06:51.731283Z","shell.execute_reply":"2024-06-23T09:06:52.301995Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'안녕하세요, 제 이름은 홍길동이고, 나이는 30살입니다.'"},"metadata":{}}]},{"cell_type":"code","source":"# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\ncombined_prompt = (\n              prompt_template\n              + PromptTemplate.from_template(\"\\n\\n아버지를 아버지라 부를 수 없습니다.\")\n              + \"\\n\\n{language}로 번역해주세요.\"\n)\n\ncombined_prompt","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:06:54.588993Z","iopub.execute_input":"2024-06-23T09:06:54.589855Z","iopub.status.idle":"2024-06-23T09:06:54.597114Z","shell.execute_reply.started":"2024-06-23T09:06:54.589822Z","shell.execute_reply":"2024-06-23T09:06:54.595936Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"PromptTemplate(input_variables=['age', 'language', 'name'], template='안녕하세요, 제 이름은 {name}이고, 나이는 {age}살입니다.\\n\\n아버지를 아버지라 부를 수 없습니다.\\n\\n{language}로 번역해주세요.')"},"metadata":{}}]},{"cell_type":"code","source":"combined_prompt.format(name=\"홍길동\", age=30, language=\"영어\")","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:04:57.649573Z","iopub.status.idle":"2024-06-23T09:04:57.650014Z","shell.execute_reply.started":"2024-06-23T09:04:57.649778Z","shell.execute_reply":"2024-06-23T09:04:57.649797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5.4.4 ChatOpenAI 인스턴스 이용하기","metadata":{}},{"cell_type":"code","source":"# ChatOpenAI 인스턴스를 생성하여 프롬프트 텍스트를 전달하고, 모델의 출력을 StrOutputParser를 통해 문자열로 변환하는 LLM 체인을 구성합니다.\n# invoke 메소드를 사용하여 파이프라인을 실행하고, 최종적으로 문자열 출력을 얻습니다. 모델의 응답은 프롬프트에 주어진 문장을 영어로 번역한 텍스트가 출력됩니다.\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.output_parsers import StrOutputParser\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",\n                 temperature=0,  # 창의성 (0.0 ~ 2.0)\n                 max_tokens=2048,  # 최대 토큰수\n                 \n                 # 본 토큰은 2024학년도 1학기 텍스트마이닝/자연어처리 수업의 과제 5를 위해서만 사용이 가능합니다.\n                 # 본 API는 6월 종강 시 까지 유지될 예정 입니다.\n                 # 본 API를 사용하는 모든 책임은 본인에게 있습니다.\n                 openai_api_key=\"sk-proj-cipaHcsyXxD93NswHF64T3BlbkFJdZaufRzviOKm6fiY4OJc\")\n                \n\nchain = combined_prompt | llm | StrOutputParser()\nchain.invoke({\"age\":30, \"language\":\"영어\", \"name\":\"홍길동\"})","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:07:05.977928Z","iopub.execute_input":"2024-06-23T09:07:05.978295Z","iopub.status.idle":"2024-06-23T09:07:07.241868Z","shell.execute_reply.started":"2024-06-23T09:07:05.978267Z","shell.execute_reply":"2024-06-23T09:07:07.240983Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'Hello, my name is Hong Gil-dong and I am 30 years old.\\n\\nI cannot call my father \"father.\"'"},"metadata":{}}]},{"cell_type":"markdown","source":"### 5.4.5 튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)","metadata":{}},{"cell_type":"code","source":"# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\nchat_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"이 시스템은 대학교의 수업에 대한 내용을 답변할 수 있습니다.\"),\n    (\"user\", \"{user_input}\"),\n])\n\nchain = chat_prompt | llm\n\nchain.invoke({\"user_input\": \"세종대학교의 텍스트마이닝 수업에 대해 알려줘.\"})","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:07:13.066547Z","iopub.execute_input":"2024-06-23T09:07:13.066887Z","iopub.status.idle":"2024-06-23T09:07:16.113282Z","shell.execute_reply.started":"2024-06-23T09:07:13.066863Z","shell.execute_reply":"2024-06-23T09:07:16.112249Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"AIMessage(content='세종대학교의 텍스트마이닝 수업은 자연어 처리와 통계학을 기반으로 한 텍스트 데이터 분석 기술을 다루는 수업입니다. 이 수업에서는 텍스트 데이터를 수집, 전처리하고, 텍스트 마이닝 기법을 활용하여 정보를 추출하고 분석하는 방법을 학습합니다. 또한, 텍스트 분류, 토픽 모델링, 감성 분석 등 다양한 텍스트 마이닝 기술을 실습을 통해 익히게 됩니다. 이 수업을 통해 학생들은 실제 텍스트 데이터를 다루며 데이터 분석 능력을 향상시킬 수 있습니다.', response_metadata={'token_usage': {'completion_tokens': 229, 'prompt_tokens': 73, 'total_tokens': 302}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a905d23f-0497-4e76-b9b9-12dab5155630-0', usage_metadata={'input_tokens': 73, 'output_tokens': 229, 'total_tokens': 302})"},"metadata":{}}]},{"cell_type":"code","source":"chat_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n    (\"user\", \"{user_input}\"),\n])\n\nchain = chat_prompt | llm\nchain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해주세요.\"})","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:07:19.867111Z","iopub.execute_input":"2024-06-23T09:07:19.867510Z","iopub.status.idle":"2024-06-23T09:07:25.991314Z","shell.execute_reply.started":"2024-06-23T09:07:19.867480Z","shell.execute_reply":"2024-06-23T09:07:25.990350Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"AIMessage(content='안녕하세요! 한국의 대표적인 관광지 3군데를 추천해드리겠습니다.\\n\\n1. 경복궁 (Gyeongbokgung Palace): 서울에 위치한 경복궁은 조선 시대의 궁궐로, 한국의 역사와 전통을 경험할 수 있는 곳입니다. 아름다운 건물과 정원, 전통 복식을 입은 경비병들의 수문장 교대식 등을 관람할 수 있습니다.\\n\\n2. 부산 해운대해수욕장 (Haeundae Beach): 부산에 위치한 해운대해수욕장은 한국에서 가장 유명한 해변 중 하나로, 아름다운 백사장과 깨끗한 바다가 매력적입니다. 여름에는 해수욕을 즐기고, 주변 맛집과 상점을 즐기며 휴양을 즐길 수 있습니다.\\n\\n3. 경주 석굴암 (Seokguram Grotto): 경주에 위치한 석굴암은 석가모니불상이 모신 동굴로, 한국의 대표적인 유네스코 세계문화유산 중 하나입니다. 아름다운 동굴 내부의 불상과 경치는 꼭 한 번 방문해보길 추천합니다.\\n\\n이렇게 한국의 다양한 매력을 경험할 수 있는 관광지들을 추천해드렸습니다. 즐거운 여행 되세요!', response_metadata={'token_usage': {'completion_tokens': 437, 'prompt_tokens': 59, 'total_tokens': 496}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d50231c9-a18b-46fb-b72e-64d116a6224f-0', usage_metadata={'input_tokens': 59, 'output_tokens': 437, 'total_tokens': 496})"},"metadata":{}}]},{"cell_type":"markdown","source":"### 5.4.6 Model Paramter 설정","metadata":{}},{"cell_type":"code","source":"# 모델 파라미터 설정\nparams = {\n    \"temperature\": 0.7,         # 생성된 텍스트의 다양성 조정\n    \"max_tokens\": 100,          # 생성할 최대 토큰 수    \n}\n\nkwargs = {\n    \"frequency_penalty\": 0.5,   # 이미 등장한 단어의 재등장 확률\n    \"presence_penalty\": 0.5,    # 새로운 단어의 도입을 장려\n}\n\n# 모델 인스턴스를 생성할 때 파라미터 설정\nmodel = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", \n                   \n                   # 본 토큰은 2024학년도 1학기 텍스트마이닝/자연어처리 수업의 과제 5를 위해서만 사용이 가능합니다.\n                   # 본 API는 6월 종강 시 까지 유지될 예정 입니다.\n                   # 본 API를 사용하는 모든 책임은 본인에게 있습니다.\n                   openai_api_key=\"sk-proj-cipaHcsyXxD93NswHF64T3BlbkFJdZaufRzviOKm6fiY4OJc\",\n                   \n                   # user-defined hyperparamters\n                   **params, model_kwargs = kwargs, stop = 100)\n\n\n# 모델 호출\nquestion = \"태양계에서 가장 큰 행성은 무엇인가요?\"\nresponse = model.invoke(input=question)\n\n# 전체 응답 출력\nprint(response)\nprint()\nprint(response.content)","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:28:18.392194Z","iopub.execute_input":"2024-06-23T09:28:18.392603Z","iopub.status.idle":"2024-06-23T09:28:19.659385Z","shell.execute_reply.started":"2024-06-23T09:28:18.392573Z","shell.execute_reply":"2024-06-23T09:28:19.658470Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"content='가장 큰 행성은 목성입니다. 목성은 태양계에서 가장 많은 물질을 포함하고 있으며, 질량과 부피 모두에서 다른 행성들을 압도합니다.' response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 29, 'total_tokens': 98}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-3619eaae-1cd5-429d-a86a-47320a5a4cc3-0' usage_metadata={'input_tokens': 29, 'output_tokens': 69, 'total_tokens': 98}\n\n가장 큰 행성은 목성입니다. 목성은 태양계에서 가장 많은 물질을 포함하고 있으며, 질량과 부피 모두에서 다른 행성들을 압도합니다.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 실습 및 과제 5.4 \n\n나만의 프롬프트를 이용하여 본인이 원하는 분야의 특정 시스템을 정의(1)하고 파라미터 값을 조정하고 해당 시스템에 대한 예시 질문을 5개 정도 만들어 langchain 모델을 최적화 하라.","metadata":{}},{"cell_type":"code","source":"# Define prompt template for movie recommendation system\nmovie_prompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"안녕하세요! 영화 추천 시스템입니다.\"),\n    (\"user\", \"어떤 영화를 좋아하세요?\"),\n    (\"system\", \"{user_favorite_genre} 장르 영화를 좋아하시는군요! 어떤 분위기의 영화를 찾으세요?\"),\n    (\"user\", \"{user_preferred_mood} 분위기의 영화를 찾아요.\"),\n    (\"system\", \"알겠습니다! {user_favorite_genre} 장르 {user_preferred_mood} 분위기의 영화를 추천해 드릴게요.\"),\n])\n\n# Set model parameters\nparams = {\n    \"temperature\": 0.8,\n    \"max_tokens\": 200,\n}\n\n# Define example inputs\nexample_inputs = [\n    \"SF 영화 중에서 액션 영화를 좋아합니다. 긴장감 넘치는 분위기의 영화를 추천해주세요.\",\n    \"코미디 영화를 좋아합니다. 가벼운 분위기의 영화를 추천해주세요.\",\n    \"멜로 영화를 좋아합니다. 감동적인 분위기의 영화를 추천해주세요.\",\n    \"스릴러 영화를 좋아합니다. 짜릿한 분위기의 영화를 추천해주세요.\",\n    \"액션 영화를 좋아합니다. 최근에 나온 영화 중에서 추천해주세요.\",\n]\n\n# Create language model instance\nmodel = ChatOpenAI(\n    model=\"gpt-3.5-turbo-0125\",\n    openai_api_key=\"sk-proj-cipaHcsyXxD93NswHF64T3BlbkFJdZaufRzviOKm6fiY4OJc\",\n    **params,\n    stop=\"\\n\",  # Pass 'stop' parameter directly to ChatOpenAI constructor\n)\n\n# Generate model responses\nfor user_input in example_inputs:\n    response = chain.invoke(user_input)  # Pass user_input directly\n    print(f\"Input: {user_input}\\nResponse: {response.content}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-23T09:55:25.833918Z","iopub.execute_input":"2024-06-23T09:55:25.834662Z","iopub.status.idle":"2024-06-23T09:55:36.911012Z","shell.execute_reply.started":"2024-06-23T09:55:25.834631Z","shell.execute_reply":"2024-06-23T09:55:36.910057Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Input: SF 영화 중에서 액션 영화를 좋아합니다. 긴장감 넘치는 분위기의 영화를 추천해주세요.\nResponse: 제가 추천하는 SF 액션 영화는 \"인터스텔라(Interstellar)\"입니다. 이 영화는 우주 여행을 다루면서도 긴장감 넘치는 스토리와 시각적 효과로 관객을 매료시킵니다. 감독 크리스토퍼 놀란의 작품으로, 과학적인 요소와 감동적인 이야기가 조화를 이루는 작품입니다. 인터스텔라를 감상하면서 새로운 우주 여행의 모험을 경험해보세요.\n\nInput: 코미디 영화를 좋아합니다. 가벼운 분위기의 영화를 추천해주세요.\nResponse: 제가 추천하는 가벼운 분위기의 코미디 영화는 \"라라랜드\"입니다. 이 영화는 로맨스와 음악을 테마로 한 유쾌한 이야기로, 매력적인 음악과 아름다운 영상이 함께 어우러져 있습니다. 코믹한 장면과 유머러스한 대사들이 풍부하게 담겨 있어 즐거운 시간을 보낼 수 있을 것입니다. 즐겁고 유쾌한 영화 감상을 기대해보세요!\n\nInput: 멜로 영화를 좋아합니다. 감동적인 분위기의 영화를 추천해주세요.\nResponse: 제가 추천하는 감동적인 멜로 영화는 \"라라랜드\"입니다. 이 영화는 음악과 로맨스가 어우러진 멋진 이야기로 많은 이들의 마음을 사로잡았습니다. 또한 \"노트북\"이나 \"타이타닉\"도 매우 감동적인 멜로 영화 중 하나로 손꼽힙니다. 이 영화들을 감상하면 여러 감정을 경험할 수 있을 것입니다.\n\nInput: 스릴러 영화를 좋아합니다. 짜릿한 분위기의 영화를 추천해주세요.\nResponse: 제가 추천하는 몇 가지 짜릿한 분위기의 스릴러 영화는 다음과 같습니다:\n\n1. \"곡성\" (The Wailing, 2016) - 한국 영화로, 미스터리한 분위기와 긴장감 넘치는 스토리가 특징입니다.\n2. \"게임\" (The Game, 1997) - 데이빗 핀처 감독의 작품으로, 예측 불가능한 전개와 긴장감 있는 연출이 인상적입니다.\n3. \"세븐\" (Se7en, 1995) - 브래드 피트와 모건 프리먼 주연의 이 영화는 다크하고 끔찍한 분위기를 자아냅니다.\n4. \"실종\" (Prisoners, 2013) - 휴 잭맨과 제이크 질렌할 주연의 이 영화는 강렬한 연기와 긴장감 넘치는 스토리로 유명합니다.\n\n이 중에서 어떤 영화를 선택하시겠습니까?\n\nInput: 액션 영화를 좋아합니다. 최근에 나온 영화 중에서 추천해주세요.\nResponse: 최근에 나온 액션 영화 중에서 추천드리는 영화는 \"블랙 위도우\"입니다. 이 영화는 마블 시네마틱 유니버스의 캐릭터 중 하나인 블랙 위도우에 대한 이야기를 다루고 있습니다. 다양한 액션 장면과 스토리가 매력적인 이 영화를 즐기실 수 있을 것입니다. 꼭 한 번 시청해보시기를 추천드립니다.\n\n","output_type":"stream"}]}]}