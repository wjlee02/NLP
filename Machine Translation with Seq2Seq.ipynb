{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rtnmm0HhFd09"
      },
      "source": [
        "# Practice 3 - Machine Translation with RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYFphTnWFd0-"
      },
      "source": [
        "## 실습 3.1 - Text Classification with RNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edrGDyoqFd0_"
      },
      "source": [
        "### Dataset Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UF73jaDcGvpu",
        "outputId": "3c9cb852-071d-49fc-eca5-7db0a329a3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8-HIl1NFd0_",
        "outputId": "90a4547f-df08-47ba-fbe9-6c39aa5ec4be",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['부산', '행', '때문', '너무', '기대하고', '봤'], ['한국', '좀비', '영화', '어색하지', '않게', '만들어졌', '놀랍']]\n"
          ]
        }
      ],
      "source": [
        "with open('/content/drive/MyDrive/2024-1-nlp-3/Korean_movie_reviews_2016.txt/Korean_movie_reviews_2016.txt', encoding='utf-8') as f:\n",
        "    docs = [doc.strip().split('\\t') for doc in f]\n",
        "    docs = [(doc[0], int(doc[1])) for doc in docs if len(doc) == 2]\n",
        "    texts, labels = zip(*docs)\n",
        "\n",
        "words_list = [doc.strip().split() for doc in texts]\n",
        "print(words_list[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N_KR4OnFd1A"
      },
      "source": [
        "### Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AemfKA5gFd1A",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "total_words = []\n",
        "for words in words_list:\n",
        "    total_words.extend(words)\n",
        "\n",
        "from collections import Counter\n",
        "c = Counter(total_words)\n",
        "\n",
        "max_features = 10000\n",
        "common_words = [ word for word, count in c.most_common(max_features)]\n",
        "# 빈도를 기준으로 상위 10000개의 단어들만 선택\n",
        "\n",
        "# 각 단어에 대해서 index 생성하기\n",
        "words_dic ={}\n",
        "for index, word in enumerate(common_words):\n",
        "    words_dic[word]=index+1\n",
        "\n",
        "# 각 문서를 상위 10000개 단어들에 대해서 index 번호로 표현하기\n",
        "filtered_indexed_words = []\n",
        "for review in words_list:\n",
        "    indexed_words=[]\n",
        "    for word in review:\n",
        "        try:\n",
        "            indexed_words.append(words_dic[word])\n",
        "        except:\n",
        "            pass\n",
        "    filtered_indexed_words.append(indexed_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbTaDXpnFd1A"
      },
      "source": [
        "### Dataset Loader for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hWxNkCL3Fd1B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# X input padding\n",
        "max_len = 40\n",
        "X = sequence.pad_sequences(filtered_indexed_words, maxlen=max_len)\n",
        "\n",
        "# y to one-hot category labeling\n",
        "y_one_hot = to_categorical(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBEMcj1rFd1B",
        "outputId": "4d25edde-6548-42a7-c9af-05b12463ffc6",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132307\n",
            "33077\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2)\n",
        "\n",
        "print(len(X_train))\n",
        "print(len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sLNr9XqFd1B"
      },
      "source": [
        "## Model Build\n",
        "### 실습 문제 3.1.1 - Bidiricetional LSTM을 구현하여 모델링을 완성하시오\n",
        "#### - from tensorflow.keras import layers 참고\n",
        "#### - 모델링 -> 실습 2 참고\n",
        "#### - https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional 참고"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hw69rfsFd1B",
        "outputId": "f83af1b4-93ac-46a5-9990-b538a821dd41",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 40, 64)            640064    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 64)                24832     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 665026 (2.54 MB)\n",
            "Trainable params: 665026 (2.54 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Embedding(max_features+1, 64, input_shape=(max_len,)))\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(2, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vqgCxPZyFd1C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# early stopping 적용\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# local에 저장하고 싶을 경우 이용\n",
        "#checkpoint_filepath = './temp/checkpoint_bi_lstm_kr'\n",
        "#mc = ModelCheckpoint(checkpoint_filepath, monitor='val_loss', mode='min', save_weights_only=True, save_best_only=True)\n",
        "\n",
        "# optimizer에 필요한 옵션 적용\n",
        "# loss와 평가 metric 적용\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKkFHYawFd1C"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZuMeM7AFd1C",
        "outputId": "935dd27c-2731-43d5-8b07-84d2225903bb",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "931/931 [==============================] - 53s 43ms/step - loss: 0.3440 - accuracy: 0.8385 - val_loss: 0.2599 - val_accuracy: 0.8923\n",
            "Epoch 2/5\n",
            "931/931 [==============================] - 16s 17ms/step - loss: 0.2488 - accuracy: 0.8993 - val_loss: 0.2573 - val_accuracy: 0.8975\n",
            "Epoch 3/5\n",
            "931/931 [==============================] - 16s 18ms/step - loss: 0.2297 - accuracy: 0.9083 - val_loss: 0.2439 - val_accuracy: 0.9008\n",
            "Epoch 4/5\n",
            "931/931 [==============================] - 15s 16ms/step - loss: 0.2165 - accuracy: 0.9141 - val_loss: 0.2411 - val_accuracy: 0.9005\n",
            "Epoch 5/5\n",
            "931/931 [==============================] - 16s 17ms/step - loss: 0.2053 - accuracy: 0.9196 - val_loss: 0.2377 - val_accuracy: 0.9014\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.1, callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "mb1vN2DgFd1D",
        "outputId": "bbf64c81-0e06-4827-e196-9bbff85bbe19",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Training history plot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuhbFz8TFd1D"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ehMyZc0Fd1D",
        "outputId": "0a2b73af-8102-4a12-f5e4-0068ae9decc2",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1034/1034 [==============================] - 7s 6ms/step - loss: 0.2442 - accuracy: 0.8984\n",
            "Loss: 0.24415920674800873\n",
            "Accuracy: 0.8983584046363831\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"Loss:\", test_loss)\n",
        "print(\"Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKpZLltgFd1D"
      },
      "source": [
        "## 실습 3.2 - Machine Translation with Seq2Seq model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R8oScJrkFd1E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hzxnnro9Fd1E"
      },
      "source": [
        "### Dataset Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-cKxQTFyFd1E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # 단어와 단어 뒤에 오는 구두점(.)사이에 공백을 생성합니다.\n",
        "    # 예시: \"he is a boy.\" => \"he is a boy .\"\n",
        "    # 참고:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")을 제외한 모든 것을 공백으로 대체합니다.\n",
        "    # w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "    w = w.strip()\n",
        "\n",
        "    # 모델이 예측을 시작하거나 중단할 때를 알게 하기 위해서\n",
        "    # 문장에 start와 end 토큰을 추가합니다.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7i5Rn_hFd1E",
        "outputId": "522fb43b-b90e-4d2e-b3d1-9a3400eb73ba",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> one day , i woke up to find that god had put hair on my face . i shaved it off . the next day , i found that god had put it back on my face , so i shaved it off again . on the third day , when i found that god had put hair back on my face again , i decided to let god have his way . that's why i have a beard . <end>\n",
            "<start> un dia , me desperte y vi que dios me habia puesto pelo en la cara . me lo afeite . al dia siguiente , vi que dios me lo habia vuelto a poner en la cara , asi que me lo afeite otra vez . al tercer dia , cuando vi que dios me habia puesto pelo en la cara de nuevo , decidi que dios se saliera con la suya . por eso tengo barba . <end>\n",
            "141543\n",
            "141543\n"
          ]
        }
      ],
      "source": [
        "# 1. 문장에 있는 억양을 제거합니다.\n",
        "# 2. 불필요한 문자를 제거하여 문장을 정리합니다.\n",
        "# 3. 다음과 같은 형식으로 문장의 쌍을 반환합니다: [영어, 스페인어]\n",
        "def create_dataset(path, num_examples):\n",
        "    ens = []\n",
        "    spas = []\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    for l in lines[:num_examples]:\n",
        "        word_pairs = [preprocess_sentence(w) for w in l.split('\\t')[:2]]\n",
        "        en, spa = word_pairs\n",
        "        ens.append(en)\n",
        "        spas.append(spa)\n",
        "    return ens, spas\n",
        "\n",
        "path_to_file = '/content/drive/MyDrive/2024-1-nlp-3/spa-eng/spa.txt'\n",
        "en, kor = create_dataset(path_to_file, None)\n",
        "\n",
        "print(en[-1])\n",
        "print(kor[-1])\n",
        "\n",
        "print(len(en))\n",
        "print(len(kor))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHmf1oAeFd1F"
      },
      "source": [
        "### Tokenizing & Padding & Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HYYgOq7OFd1F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                           padding='post')\n",
        "    return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ODXgCPENFd1F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "    # 전처리된 타겟 문장과 입력 문장 쌍을 생성합니다.\n",
        "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mIVNnpwFd1G",
        "outputId": "1452e217-9efa-4fce-c87d-dba0853e621b",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8000 8000 2000 2000\n"
          ]
        }
      ],
      "source": [
        "# 언어 데이터셋을 아래의 크기로 제한하여 훈련과 검증을 수행합니다.\n",
        "num_examples = 10000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# 타겟 텐서와 입력 텐서의 최대 길이를 계산합니다.\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "# 훈련 집합과 검증 집합을 80대 20으로 분리합니다.\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 훈련 집합과 검증 집합의 데이터 크기를 출력합니다.\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdbJ8LbYFd1G",
        "outputId": "fc91a762-3960-40e3-bdff-0cf1bd574b7e",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "17 ----> se\n",
            "1412 ----> quemo\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "8 ----> it\n",
            "721 ----> burned\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ]
        }
      ],
      "source": [
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t!=0:\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
        "\n",
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPjcwXaZFd1G"
      },
      "source": [
        "## Model Build for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zrGj__3yFd1G",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 512\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJDMJcUVFd1G",
        "outputId": "5549127f-c614-4285-e5f8-8ac68700acfc",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([128, 13]), TensorShape([128, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# dataset 크기 출력\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OXmTCHTFd1H"
      },
      "source": [
        "## 인코더 모델과 디코더 모델 쓰기\n",
        "어텐션(attention)을 가진 인코더-디코더 모델을 수행합니다. 어텐션(attention)은 TensorFlow Neural Machine Translation (seq2seq) tutorial에서 읽을 수 있습니다. 이 예제는 더 최신의 API 집합을 사용합니다. 이 노트북은 seq2seq 튜토리얼로부터 어텐션 방정식을 수행합니다. 아래의 다이어그램은 각각의 입력 단어가 어텐션 메커니즘에 의해 가중치가 할당된 모습입니다. 이러한 어텐션 메커니즘은 디코더가 문장에서 다음 단어를 예측하기 위해 사용됩니다. 아래의 그림과 공식은 Luong's paper에서 나온 어텐션 메커니즘의 예시입니다.\n",
        "\n",
        "![image.png](attachment:c0952e5c-9c02-49c8-9117-f3fcf6b60447.png)![image.png](attachment:c0444d39-21a8-43e4-9792-86205b74b8ed.png)\n",
        "\n",
        "이 튜토리얼은 인코더를 위해 Bahdanau 어텐션을 사용합니다. 단순화된 형태로 쓰기 전에 표기법을 아래와 같이 정의합니다:\n",
        "\n",
        "FC = 완전 연결(Dense)층\n",
        "EO = 인코더 결과\n",
        "H = 은닉 상태(hidden state)\n",
        "X = 디코더에 대한 입력\n",
        "그리고 다음은 슈도코드입니다:\n",
        "\n",
        "스코어(score)는 FC(tanh(FC(EO) + FC(H)))로 계산합니다.\n",
        "어텐션 가중치는 softmax(score, axis = 1)로 계산합니다. 기본적으로 소프트맥스는 마지막 축을 적용하지만 스코어(score)의 형태가 (batch_size, max_length, hidden_size)이기 때문에 첫번째 축을 적용합니다. Max_length은 입력의 길이입니다. 각각의 입력에 가중치를 할당하려고 시도하기 때문에 소프트맥스는 그 축을 적용할 수 있습니다.\n",
        "컨텍스트 벡터(context vector)는 sum(어텐션 가중치 * EO, axis = 1)로 계산합니다. 위와 같은 이유로 첫번째 축을 선택합니다.\n",
        "임베딩 결과(embedding output)는 디코더 X에 대한 입력이 임베딩층을 통과한 결과입니다.\n",
        "병합된 벡터(merged vector)는 concat(임베딩 결과, 컨텍스트 백터(context vector))와 같습니다.\n",
        "그런 다음 병합된 벡터는 GRU에 주어집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoqxmiakFd1H"
      },
      "source": [
        "### 실습 문제 3.2.1 - Encoder & Attention & Decoder 각 Class 이해하고 주석 달기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wRQ_0trqFd1H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        # 배치 크기와 은닉 상태 크기를 설정합니다.\n",
        "        # 입력 토큰을 벡터로 변환하는 임베딩 레이어를 설정합니다.\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # GRU 레이어를 설정합니다. 이 레이어는 시퀀스를 처리하고 인코더 상태를 반환합니다.\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        # 입력을 임베딩 레이어에 통과시킵니다.\n",
        "        x = self.embedding(x)\n",
        "        # 임베딩된 입력을 GRU에 통과시킵니다.\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        # 숨겨진 상태를 0으로 초기화합니다.\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        # 어텐션 가중치를 계산하는데 사용되는 완전 연결 레이어들을 설정합니다.\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # 어텐션 점수를 계산합니다.\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "        # 소프트맥스를 적용하여 어텐션 가중치를 계산합니다.\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        # 가중 평균을 계산하여 컨텍스트 벡터를 생성합니다.\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        # 배치 크기와 디코더의 은닉 상태 크기를 설정합니다.\n",
        "        # 목표 토큰을 임베딩하는데 사용되는 임베딩 레이어를 설정합니다.\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        # 디코더 입력 및 컨텍스트 벡터를 처리하는데 사용되는 GRU 레이어를 설정합니다.\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        # 출력 로짓을 생성하기 위한 완전 연결 레이어를 설정합니다.\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        # 어텐션 메커니즘을 설정합니다.\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # 컨텍스트 벡터와 어텐션 가중치를 계산합니다.\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        # 목표 토큰을 임베딩 레이어에 통과시킵니다.\n",
        "        x = self.embedding(x)\n",
        "        # 컨텍스트 벡터와 임베딩된 입력을 연결합니다.\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        # 연결된 벡터를 GRU에 통과시킵니다.\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        # 출력 로짓을 생성합니다.\n",
        "        x = self.fc(output)\n",
        "        return x, state, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVsVk3BIFd1H"
      },
      "source": [
        "### Encoder-Attention-Decoder 구현"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFpLiI5qFd1H",
        "outputId": "0976fa05-6dd3-44f7-ff4d-ce82ae604910",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (128, 13, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (128, 1024)\n",
            "Attention result shape: (batch size, units) (128, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (128, 13, 1)\n",
            "Decoder output shape: (batch_size, vocab size) (128, 2263)\n"
          ]
        }
      ],
      "source": [
        "# encoder\n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# 샘플 입력\n",
        "sample_hidden = encoder.initialize_hidden_state()  # encoder의 초기 hidden state 설정합니다.\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)  # encoder를 통해 입력 batch 처리합니다.\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))  # encoder 출력 shape 출력합니다.\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))  # encoder 최종 hidden state의 shape 출력합니다.\n",
        "\n",
        "# encoder-decoder attention\n",
        "attention_layer = BahdanauAttention(10)  # BahdanauAttention 객체 생성, attention units는 10으로 설정합니다.\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)  # attention 과 weights 계산합니다.\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))  # attention shape 출력합니다.\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))  # attention 가중치의 shape 출력합니다.\n",
        "\n",
        "# decoder\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)  # Decoder 객체를 생성합니다.\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)  # decoder를 통해 샘플 입력 처리합니다.\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))  # decoder 출력 shape 출력합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhNA2vO3Fd1H"
      },
      "source": [
        "### Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6hvUpOMFd1H",
        "outputId": "535a88ff-1271-476c-f3f8-b09ed0c066bb",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.AdamW(lr=0.001)\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJwvCnXFd1I"
      },
      "source": [
        "### Training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IXmEpktFd1I"
      },
      "source": [
        "언어 모델 훈련하기\n",
        "1. 인코더 결과와 인코더 은닉 상태(hidden state)를 반환하는 인코더를 통해서 입력을 전달합니다.\n",
        "2. 인코더 결과, 인코더 은닉 상태(hidden state), 디코더 입력 (start 토큰)을 디코더에 전달합니다.\n",
        "3. 전달 받은 값을 통해 디코더는 예측 값과 디코더 은닉 상태(hidden state)를 반환합니다.\n",
        "4. 그 다음에 디코더 은닉 상태(hidden state)가 다시 모델에 전달되고 예측 값을 사용하여 손실을 계산합니다.\n",
        "5. 디코더에 대한 다음 입력을 결정하기 위해서 교사 강요(teacher forcing)를 사용합니다.\n",
        "6. 교사 강요(teacher forcing)는 타겟 단어가 디코더에 다음 입력으로 전달하기 위한 기술입니다.\n",
        "7. 마지막 단계는 그레디언트(gradients)를 계산하여 이를 옵티마이저(optimizer)와 역전파(backpropagate)에 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hmmCpQCmFd1I",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_step(inp, targ, enc_hidden):\n",
        "    loss = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        # encoder\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        # decoder\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # 교사 강요(teacher forcing) - 다음 입력으로 타겟을 피딩(feeding)합니다.\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # enc_output를 디코더에 전달합니다.\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # 교사 강요(teacher forcing)를 사용합니다.\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRiMMM6mFd1I",
        "outputId": "5b2ba57c-f4cd-45a4-f0d1-ad28fadad9be",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7a2f2a864430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7a2f2a864430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / Batch 0 / Loss 4.5792 / Time taken 3.9370551109313965 sec\n",
            "Epoch 1 / Loss 2.1994\n",
            "Time taken for 1 epoch 30.534836292266846 sec\n",
            "\n",
            "Epoch 2 / Batch 0 / Loss 1.6409 / Time taken 0.3307065963745117 sec\n",
            "Epoch 2 / Loss 1.4925\n",
            "Time taken for 2 epoch 21.68673038482666 sec\n",
            "\n",
            "Epoch 3 / Batch 0 / Loss 1.2420 / Time taken 0.33178091049194336 sec\n",
            "Epoch 3 / Loss 1.1105\n",
            "Time taken for 3 epoch 20.57959222793579 sec\n",
            "\n",
            "Epoch 4 / Batch 0 / Loss 0.7990 / Time taken 0.3283991813659668 sec\n",
            "Epoch 4 / Loss 0.7858\n",
            "Time taken for 4 epoch 40.94848132133484 sec\n",
            "\n",
            "Epoch 5 / Batch 0 / Loss 0.5352 / Time taken 0.5177557468414307 sec\n",
            "Epoch 5 / Loss 0.5237\n",
            "Time taken for 5 epoch 20.975592851638794 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 이 파트가 매우 오래걸림\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(inp, targ, enc_hidden)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} / Batch {} / Loss {:.4f} / Time taken {} sec'.format(epoch + 1,\n",
        "                                                                                 batch,\n",
        "                                                                                 batch_loss.numpy(),\n",
        "                                                                                 time.time() - start))\n",
        "    # 에포크가 2번 실행될때마다 모델 저장 (체크포인트)\n",
        "    #if (epoch + 1) % 2 == 0:\n",
        "    #    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Epoch {} / Loss {:.4f}'.format(epoch + 1,\n",
        "                                          total_loss / steps_per_epoch))\n",
        "    print('Time taken for {} epoch {} sec\\n'.format(epoch + 1,\n",
        "                                                    time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GbTRcF0TFd1I",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # 나중에 어텐션 가중치를 시각화하기 위해 어텐션 가중치를 저장합니다.\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # 예측된 ID를 모델에 다시 피드합니다.\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VZ9k2YpUFd1J",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5OMuwzxFd1J",
        "outputId": "c4a34500-5c86-4462-ff74-fc844910440d",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it's too here . <end> \n"
          ]
        }
      ],
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGQYZSrTFd1J"
      },
      "source": [
        "### 실습 문제 3.2.2 - BLEU 스코어 구현하기\n",
        "#### - Dataset Sample에서 Test 만들기\n",
        "#### - BLEU Score 구현\n",
        "#### - 학습된 모델로 BLEU Score로 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "KK4TnBnSFd1J"
      },
      "outputs": [],
      "source": [
        "# 데이터 셋의 10프로를 테스트 셋으로 설정\n",
        "input_tensor_val, input_tensor_test, target_tensor_val, target_tensor_test = train_test_split(input_tensor_val, target_tensor_val, test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBXRbnhommc8",
        "outputId": "57eebdbb-582c-43e0-b018-27e7a08e7196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.242971150164143\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "#BLEU Score\n",
        "def bleu_score(references, candidates):\n",
        "    smoothie = SmoothingFunction().method4\n",
        "    bleu_scores = []\n",
        "    for ref, cand in zip(references, candidates):\n",
        "        ref_tokens = ref.split()\n",
        "        cand_tokens = cand.split()\n",
        "        bleu_scores.append(\n",
        "            corpus_bleu([[ref_tokens]], [cand_tokens], weights=(0.25, 0.25, 0.25, 0.25), smoothing_function=smoothie)\n",
        "        )\n",
        "    return sum(bleu_scores) / len(bleu_scores)\n",
        "predictions = []\n",
        "references = []\n",
        "for input_seq, target_seq in zip(input_tensor_test, target_tensor_test):\n",
        "    prediction, _, _ = evaluate(inp_lang.sequences_to_texts([input_seq])[0])\n",
        "    target = targ_lang.sequences_to_texts([target_seq])[0]\n",
        "    predictions.append(prediction)\n",
        "    references.append(target)\n",
        "bleu_score = bleu_score(references, predictions)\n",
        "print(f\"BLEU Score: {bleu_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6gZPCb9Fd1J"
      },
      "source": [
        "### 실습 문제 3.2.3 - Hyperparmeter 튜닝으로 번역 성능 높이기\n",
        "#### - 어떤 방안을 활용해 성능을 높였는지?\n",
        "#### - 성능이 정량적으로 얼마나 높아졌는지?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lba8QXyTFd1J"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zTPrp21_h9uP"
      },
      "execution_count": 30,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 8315984,
          "sourceId": 75475,
          "sourceType": "competition"
        },
        {
          "datasetId": 4852358,
          "sourceId": 8193063,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30702,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}